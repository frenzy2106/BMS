---
title: "Big Mart Sales"
output: html_notebook
---


```{r}
# Reading into data frames and loading required packages
library(dplyr)
library(ggplot2)
library(rpart)
library(data.table)
setwd("C:/Users/ankit/Desktop/R/big mart sales/")
train <- read.csv("Train_UWu5bXk.csv",na.strings = c("","NaN"," "), stringsAsFactors = FALSE)
test <- read.csv("Test_u94Q5KV.csv",na.strings = c("","NaN"," "),stringsAsFactors = FALSE)
test$Item_Outlet_Sales <- as.factor("NA")
```

```{r}
#Combining training and test set 
ind <- c("Item_Identifier","Outlet_Identifier")
#df.sales <- rbind(train[,!(names(train)) %in% ind],test[,!(names(test)) %in% ind])
df.sales <- rbind(train,test)
#Missing values Summary
Variable <- colnames(df.sales)
NA_count <- sapply(df.sales, function(x) sum(is.na(x)))
miss_summ <- data.frame(Variable,NA_count,row.names = NULL)
miss_summ %>%
  arrange(desc(NA_count))
```

```{r}
#Treatment of missing values using Product ID
item_summ <- unique(na.omit(df.sales[,c("Item_Identifier","Item_Weight")]))
df.sales <- df.sales[,!(names(df.sales)) %in% c('Item_Weight')]
df.sales <- full_join(df.sales,item_summ,by = "Item_Identifier")
```

```{r}
outlet_summ <- df.sales %>%
  group_by(Outlet_Identifier,Outlet_Size,Outlet_Type,Outlet_Establishment_Year,Outlet_Location_Type) %>%
  summarise(median.visibility = median(Item_Visibility),count = n())
```

```{r}
#There are 3 outlets with missing outlet size
# We can only guess it for Outlet010 with some certainty
df.sales$Outlet_Size[df.sales$Outlet_Identifier == "OUT010"] = "Small"
df.sales$Outlet_Size[is.na(df.sales$Outlet_Size)] = "Other"

```

```{r}
#Cleaning Data
#Item Visibility can't be zero

item_summ2 <- df.sales %>%
  group_by(Item_Identifier) %>%
  filter(Item_Visibility != 0) %>%
  summarise(med.vis = median(Item_Visibility))

df.sales <- full_join(df.sales,item_summ2,by = "Item_Identifier")
df.sales$Item_Visibility <- ifelse(df.sales$Item_Visibility == 0,df.sales$med.vis,df.sales$Item_Visibility)
df.sales <- df.sales[,!(names(df.sales) %in% c("med.vis"))]

#Clean Fat content variable
df.sales$Item_Fat_Content[df.sales$Item_Fat_Content == "LF"] = "Low Fat"
df.sales$Item_Fat_Content[df.sales$Item_Fat_Content == "low fat"] = "Low Fat"
df.sales$Item_Fat_Content[df.sales$Item_Fat_Content == "reg"] = "Regular"
df.sales$Item_Fat_Content[substr(df.sales$Item_Identifier,1,2) == "NC"] = "Non-Edible"
```

```{r}
#Feature Engineering
df.sales$Item_Type <- substr(df.sales$Item_Identifier,1,2)
df.sales$Year <- 2017 - df.sales$Outlet_Establishment_Year
df.sales$Item_Outlet_Sales <- as.numeric(df.sales$Item_Outlet_Sales)

df.sales <- df.sales %>% 
  group_by(Item_Identifier) %>% 
  mutate(Mean_Sales_Item = mean(Item_Outlet_Sales, na.rm = T))

df.sales <- df.sales %>% 
  group_by(Outlet_Identifier) %>% 
  mutate(Mean_Sales_Outlet = mean(Item_Outlet_Sales, na.rm = T))

df.sales$MRP_Level <- as.factor(
  ifelse(df.sales$Item_MRP < 69, "Low",
         ifelse(df.sales$Item_MRP < 136, "Medium",
                ifelse(df.sales$Item_MRP < 203, "High", "Very_High"))))
```

```{r}
library(dummies)
library(purrr)

df.sales.new <- droplevels(dummy.data.frame(as.data.frame(df.sales), names = c("Item_Fat_Content", "Item_Type", "Outlet_Size", "Outlet_Location_Type", "Outlet_Type", "MRP_Level"), sep = "_"))

df.sales.new <- as.data.frame(map(df.sales.new, as.numeric))
y_train <- train$Item_Outlet_Sales
# new_train <- new_train[,!names(new_train) %in% c('Purchase')]

```

XGBoost Implementation

```{r}
df.sales.new <- df.sales.new[,names(df.sales.new) %in% c("Item_MRP", "Outlet_Type_Grocery.Store", "Outlet_Type_Supermarket.Type3", "Outlet_Type_Supermarket.Type1", "Outlet_Location_Type_Tier.1", "Outlet_Location_Type_Tier.2", "Outlet_Location_Type_Tier.3", "MRP_Level_High", "MRP_Level_Low", "MRP_Level_Medium", "MRP_Level_Very_High")]

new_train <- df.sales.new[1:nrow(train),]
new_test <- df.sales.new[-(1:nrow(train)),]
library(xgboost)
dtrain <- xgb.DMatrix(as.matrix(new_train),label = y_train)
dtest <- xgb.DMatrix(as.matrix(new_test))

xgb_params = list(
  booster = 'gbtree',
  objective = 'reg:linear',
  colsample_bytree=0.8,
  eta=0.05,
  max_depth=3,
  subsample=0.8,
  seed=5,
  silent=TRUE)

bst <- xgb.train(data = dtrain, params = xgb_params,nround=113)

xgb.cv(xgb_params, dtrain, nrounds = 5000, nfold = 4, early_stopping_rounds = 100)
    ```

```{r}
pred <- predict(bst,dtest)
sub_file <- data.frame(Item_Identifier = test$Item_Identifier, Outlet_Identifier = test$Outlet_Identifier, Item_Outlet_Sales = pred)
write.csv(sub_file, 'xgb_sales_nr_113.csv',row.names = FALSE)
```

```{r}
model.names = dimnames(dtrain)[[2]]

importance_matrix = xgb.importance(model.names, model = bst)

xgb.plot.importance(importance_matrix[1:10])
```

```{r}
library(h2o)
localH2O <- h2o.init(nthreads = -1)
 h2o.init()
```



```{r}
df.sales.new <- df.sales.new[,names(df.sales.new) %in% c("Item_MRP", "Outlet_Type_Grocery.Store", "Outlet_Type_Supermarket.Type3", "Outlet_Type_Supermarket.Type1", "Outlet_Location_Type_Tier.1", "Outlet_Location_Type_Tier.2", "Outlet_Location_Type_Tier.3", "MRP_Level_High", "MRP_Level_Low", "MRP_Level_Medium", "MRP_Level_Very_High", "Item_Outlet_Sales")]
c.train <- df.sales.new[1:nrow(train),]
c.test <- df.sales.new[-(1:nrow(train)),]
train.h2o <- as.h2o(c.train)
test.h2o <- as.h2o(c.test)
```

```{r}
system.time(
             dlearning.model <- h2o.deeplearning(y = 'Item_Outlet_Sales',
             training_frame = train.h2o,
             epoch = 60,
             hidden = c(8, 8),
             activation = "Rectifier",
             seed = 1122
             )
)
```

```{r}
h2o.performance(dlearning.model)
```

```{r}
predict.dl2 <- as.data.frame(h2o.predict(dlearning.model, test.h2o))
sub_file_ens <- data.frame(Item_Identifier = test$Item_Identifier, Outlet_Identifier = test$Outlet_Identifier, Item_Outlet_Sales = 0.7 * predict.dl2$predict + 0.3 * pred)
write.csv(sub_file_ens, 'ens_sales_xgb_nn.csv',row.names = FALSE)
```



